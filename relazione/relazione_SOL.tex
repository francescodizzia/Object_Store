\title{\textbf{{\Huge Progetto di Sistemi Operativi e Laboratorio (a.a. 2018-2019)}}\\
\Huge{\vspace{8mm} Object Store}}

\author{
\\
\\ \huge {Francesco D'Izzia}
}
\date{
\begin{Large}
Matricola 544107\\
Corso B
\end{Large}
}


\documentclass[11pt]{article}
\usepackage{fullpage}
\usepackage{titling}
\usepackage{titlesec}
\usepackage{hyperref}
\usepackage[magyar]{babel}
\usepackage{t1enc}
\usepackage{fancyvrb}
\usepackage{lipsum}
\usepackage{titletoc}



\begin{document}
\begin{titlingpage}
\maketitle

\renewcommand{\contentsname}{Indice}

\tableofcontents
\end{titlingpage}



\section{Struttura del progetto}
\begin{flushleft}

Il progetto è stato strutturato in più file al fine di garantire maggiore flessibilità, modularità e organizzazione del codice stesso. Di seguito è possibile trovare la lista dei file con una sintetica descrizione del loro ruolo.

\subsection{File sorgenti}
\begin{itemize}
	\item \emph{server.c} : si occupa di gestire il server, mettendosi in attesa dei client e servendoli creando un relativo thread worker. Una volta
	dato l'arresto con gli opportuni segnali (di cui si occuperà creando un thread apposito per la gestione dei suddetti), sarà compito suo dare l'avviso di terminazione ai relativi thread, in modo tale da permettere un processo di terminazione "gentile" e pulita. 
	
	\item \emph{lib.c} : il vero "cuore" dell'Object Store, ovvero la libreria contenente le funzioni richieste (os\_connect, os\_store, etc...)
	
	\item \emph{common.c} : contiene una serie di funzioni, variabili e macro ausiliarie necessarie sia al server, che alla libreria.
	
	\item \emph{thread\_worker.c} : descrive il loop eseguito dai vari thread worker generati dal server, legge l'header inviato dal client e lo manda al parser.
	
	\item \emph{parser.c} : effettua il parsing delle richieste, una volta decodificata la request procede con l'esecuzione dell'operazione richiesta dal client.
	
	\item \emph{client.c} : è il client che adopera le funzioni implementate nella libreria per l'invio delle varie richieste. Verrà richiamato dallo script bash per l'esecuzione dei test.
	
	\item \emph{hashtable.c} : implementazione delle tabelle hash e delle relative funzioni.

\end{itemize}


\end{flushleft}

\subsection{Script bash}
\begin{flushleft}
\begin{itemize}
\item \emph{test\_base.sh} : si occuperà di eseguire i test base (viene lanciato  dal comando \texttt{make test}).

\item \emph{testsum.sh} : stampa a schermo un resoconto dei test eseguiti e manda il segnale SIGUSR1 al server (anch'esso viene lanciato da make test, subito dopo l'esecuzione dei test).

\item \emph{test\_files.sh} : esegue un piccolo test extra (quest'ultimo viene lanciato dal comando \texttt{make test2}), vedere la sezione \textbf{Test e note} per maggiori informazioni.

\item \emph{monitor.sh} : script usato durante lo sviluppo e il debugging del progetto, per verificare la corretta chiusura dei thread legati al server.

\item \emph{usr1.sh} : altro piccolo script usato durante il debugging, invia semplicemente un segnale di tipo SIGUSR1 al server, che provvederà a stampare le statistiche a schermo.

\end{itemize}
\end{flushleft}

\section{Overview e scelte progettuali}
\begin{flushleft}
Data l'impostazione del progetto, aldilà di alcuni vincoli legati alla rigidità del protocollo, è stato dato molto spazio riguardo alle possibili scelte implementative e concettuali personali.\\In questa sezione cercherò di presentarle e di motivarle brevemente.
\end{flushleft}


\vspace{1mm}



\subsection{Gestione delle richieste dei client}
\begin{flushleft}
Il server comprende un ciclo all'interno del quale esso si mette in attesa delle connessioni da parte dei client e attraverso una \texttt{select} con timer decide quando è il momento di servire un determinato client, creando un thread worker apposito che si occupa di prendersene cura.
\\~\\
Nelle fasi iniziali del progetto, al posto della select avevo optato per un file descriptor \texttt{non bloccante}, tuttavia ho deciso in seguito di cambiare perché da alcuni test effettuati, osservando attentamente l'utilizzo delle risorse e in particolare della CPU, quest'ultima, anche in assenza di connessioni da parte dei client, continuava a iterare nel ciclo, consumando continuamente il processore e avvicinandosi ad uno stato di \emph{busy waiting}.
\\~\\
La select, scelta con un timer opportuno (in questo caso pari a \texttt{10 ms}), permette di alleggerire il carico di lavoro della CPU, senza dover rinunciare alla necessità da parte del server di non fossilizzarsi in attesa che un client si connetta, voglio infatti evitare che il server possa diventare "ostaggio" dei client.
\end{flushleft}


\vspace{2mm}

\subsection{Thread Worker}
\begin{flushleft}
Ognuno dei thread worker si occupa di leggere l'header, inviato dal rispettivo client e di richiamare il parser per effettuare la successiva decodifica ed esecuzione della richiesta data.\\
In questo caso invece ho ritenuto ragionevole utilizzare un file descriptor \textbf{non} bloccante: difficilmente avrò dei client che rimangono connessi per diverso tempo senza fare assolutamente nulla, ma devo comunque fare in modo che il thread (e quindi il server, che lo aspetta) non si blocchi e diventi schiavo del client, basti pensare ad un client del tipo:

\begin{Verbatim} 
	os_connect("user");
	sleep(5);
	os_disconnect();
\end{Verbatim}

Se il fd non fosse di tipo unblocking, non sarebbe possibile in questo caso far terminare (in modo pulito e ordinato, maggiori dettagli poco più avanti) il server e i thread nel bel mezzo dei 5 secondi di pausa del client, una cosa sicuramente poco gradita, che però grazie al fd non bloccante riusciamo a evitare.

\end{flushleft}

\newpage

\subsection{Terminazione "gentile" del server e dei thread}
\begin{flushleft}


Il server e i thread condividono una variabile booleana \texttt{running}, di tipo volatile sig\_atomic\_t: il continuo operare del server e dei thread è dettato da tale variabile, infatti finché è settata a true il loop andrà avanti, sia quello di accettazione dei client, che quello di decodifica delle richieste presente nel thread worker (notare che se il client ha finito e si è già disconnesso il corrispettivo thread worker terminerà ugualmente, a prescindere dalla variabile running).
\\~\\
Il server, come già specificato nella traccia, avvia la procedura di terminazione quando riceve un segnale (diverso da SIGUSR1): tutto ciò che farà l'handler dei segnali in quel caso sarà semplicemente settare a false la variabile running, in modo tale da interrompere le continue iterazioni dei cicli, si andranno dunque a eseguire determinate istruzioni per assicurarsi di uscire in modo sicuro.
\\~\\
Nel caso del server, esso si metterà in attesa della terminazione di tutti gli altri thread worker, sospendendosi sulla variabile di condizione \texttt{empty}, mentre nel caso dei thread si andrà prima a decrementare la variabile \texttt{n\_clients}, che rappresenta il numero di client attualmente connessi al server, dopodiché si controllerà nuovamente il valore: nel caso sia uguale a zero, verrà mandata una signal al server per svegliarlo, che fatto ciò potrà deallocare le risorse e poi terminare.

\end{flushleft}

\subsection{Signal Handler Thread}
\begin{flushleft}

La gestione dei segnali, considerando l'ambiente multi-threaded, ho deciso di gestirla utilizzando un thread apposito, tale thread, finché la variabile running è settata a true, rimane in attesa dei segnali attraverso la \texttt{sigwait}, per poi andare a verificare la tipologia di segnale ricevuto: nel caso sia un SIGUSR1 allora procederò verso la stampa delle statistiche, in ogni altro caso setto il flag running a false e comincio il necessario per la terminazione. 
\\
Prima di generare il thread avrò già mascherato i vari segnali, eseguendo \texttt{sigfillset} per comunicare di voler bloccare tutti i segnali e settando la maschera con \texttt{pthread\textunderscore sigmask}.

\end{flushleft}

\subsection{Stampa delle statistiche}
\begin{flushleft}

La stampa delle statistiche, essendo richiamata direttamente dal signal handler, necessita di utilizzare funzioni \emph{async-signal-safe}: per questo motivo avevo pensato di utilizzare una write piuttosto che una printf per stampare le informazioni a schermo, tuttavia, dato che sarebbe risultato scomodo convertire alcune tipologie di dati in stringhe (così da stamparli con write), ho quindi cambiato approccio, facendo in modo di stampare le statistiche al di fuori dell'handler, dal quale invece verrà settato un flag nel caso di SIGUSR1, che verrà controllato nel loop del server e, nel caso sia settato a true, procederà con la stampa delle statistiche, che essendo fuori dall'handler potrà utilizzare printf senza problemi.
Il calcolo delle statistiche viene effettuato mediante la funzione ricorsiva \texttt{ftw} (\emph{file-tree-walk}), funzione async-signal-safe e thread-safe.
\\~\\
Le seguenti informazioni vengono stampate: size totale dello store (in byte e MB), numero di oggetti, numero di sottocartelle all'interno della cartella \texttt{data} e numero di client attualmente connessi.  
\end{flushleft}

\newpage

\subsection{Parsing delle richieste}
\begin{flushleft}
Per quanto riguarda il parser: si occupa semplicemente, sfruttando il formato definito dal protocollo, di spezzettare la richiesta in più campi (tipo di operazione, nome dell'utente/dell'oggetto, lunghezza dell'eventuale dato inviato e newline). Il comportamento è abbastanza semplice per quanto riguarda la maggior parte delle richieste: di default leggo uno standard di 512 byte, che saranno sicuramente abbastanza per leggere fino al newline, dato che al caso più impegnativo oltre all'header di base e spazi (una decina di byte) dovrò leggere il nome utente (che avrà un massimo di 255 byte, limite dettato da UNIX stesso) e un certo numero di cifre numeriche che descrive la lunghezza.\\Un po' più interessanti da analizzare sono la STORE e la RETRIEVE (essenzialmente simmetriche nell'implementazione).\\~\\

La STORE calcola, in base alla dimensione di ciò che ha letto nell'header, se è necessaria una ulteriore read di \texttt{x} byte per concludere la lettura, dove x è dato dalla differenza tra la lunghezza dei dati e la quantità di dati già letti nella prima read. Se invece ha già letto tutti i dati con la prima read può procedere direttamente alla creazione dell'oggetto.
\\~\\
La RETRIEVE essenzialmente funziona in modo quasi identico, la differenza consiste nel fatto che la lettura dei dati viene fatta dal client (dato che riceverà l'header di "risposta" con i dati dal server), andrà a tokenizzare l'header ricevuto e farà lo stesso calcolo della STORE per capire se ha finito di leggere o meno i dati. 

\end{flushleft}

\subsection{Gestione di più client dello stesso utente}
\begin{flushleft}

Dalla traccia veniva detto che i nomi erano garantiti essere distinti tra i vari client, non era però specificato se era possibile una situazione in cui uno stesso utente poteva avere o meno più client registrati e operanti nello stesso momento.\\

Ho scelto quindi di gestire il suddetto caso facendo in modo di registrare gli utenti in una struttura dati condivisa, così da poter verificare, prima di ogni registrazione, che l'utente non sia già connesso attraverso un altro client.\\

Nel caso in cui sia già presente un utente collegato con quel nome, il secondo utente fallirà l'operazione di registrazione, restituendo \texttt{KO Multiple clients with the same username \textbackslash n}.\\~\\
Inizialmente la struttura dati che avevo adoperato era una semplice \emph{linked list}, tuttavia in seguito ad alcuni test ed esperienze dirette ho deciso di passare ad una tabella hash, principalmente per questioni di velocità. 
\\~\\
Dato che la tabella hash è condivisa, ho piazzato una mutex per ogni cella della tabella (quindi una per ogni linked list).
La tabella hash gestisce essenzialmente delle stringhe (i nomi degli utenti).\\ Dopo una ricerca relativa a delle funzioni hash operanti su stringhe, ho pensato di scegliere la funzione hash \textbf{djb2} di Dan Bernstein (\url{http://www.cse.yorku.ca/~oz/hash.html}), che si è distinta tra le altre candidate per le ottime performance registrate.
 

\end{flushleft}

\newpage

\section{Test e note}
\begin{flushleft}

\subsection{Esecuzione dei test}
Per eseguire i test sarà prima necessario, dopo aver compilato con il comando \texttt{make all}, aver avviato il server (avviandolo normalmente da shell con \texttt{./server} o eseguendo \texttt{make dserver} qualora si voglia avviarlo con valgrind e relativi flags).\\
Avviato il server, basterà dare il comando \texttt{make test} per eseguire i test e vederne i risultati.\\~\\

\subsection{Test supplementare}
Oltre ai test base, per assicurarmi del corretto funzionamento durante lo sviluppo, ho voluto testare il comportamento nel caso in cui i client andavano a inviare dati binari di diverse tipologie, magari di uso quotidiano, come immagini e file pdf. In questo micro-test, ci sono quattro utenti che vanno a caricare quattro tipologie di file (due immagini, un pdf e una gif animata) e richiedono lo storing dei suddetti oggetti tramite libreria. I file originali sono presenti nella directory \texttt{testFiles}: al termine di questo test (eseguibile tramite il comando \texttt{make test2}) se il tutto è andato a buon fine sarà possibile verificare manualmente la presenza dei vari file all'interno dei determinati spazi utente nella directory \texttt{data}.\\~\\
È possibile provare ad aggiungere ulteriori tipologie di file nella cartella testFiles, per poi avviare da shell il client digitando qualcosa del tipo:\\ \texttt{./client "nome\_utente" 4 "./testFiles/nome\_file" "nome\_oggetto"}.

\subsection{Ulteriori info}
Il progetto è stato testato sui seguenti OS:
\begin{itemize}
\item Ubuntu 18.10
\item Xubuntu 14.10 (macchina virtuale ufficiale del corso)
\end{itemize}

\end{flushleft}

\end{document}
